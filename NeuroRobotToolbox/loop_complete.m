
clear
clc

load env.mat
load lgraph_1.mat

obsInfo = getObservationInfo(env);
actInfo = getActionInfo(env);
net = dlnetwork(lgraph_1);
critic = rlQValueFunction(net,obsInfo,actInfo,...
    "ObservationInputNames",["pendImage","angularRate"],"ActionInputNames","torque");

criticOpts = rlOptimizerOptions('LearnRate',1e-03,'GradientThreshold',1);

agentOpts = rlDQNAgentOptions(...
    'UseDoubleDQN',false,...    
    'CriticOptimizerOptions',criticOpts,...
    'ExperienceBufferLength',1e6,... 
    'SampleTime',env.Ts);
agentOpts.EpsilonGreedyExploration.EpsilonDecay = 1e-5;

agent = rlDQNAgent(critic,agentOpts);

trainOpts = rlTrainingOptions(...
    'MaxEpisodes',5000,...
    'MaxStepsPerEpisode',500,...
    'Verbose',false,...
    'Plots','training-progress',...
    'StopTrainingCriteria','AverageReward',...
    'StopTrainingValue',-1000);

